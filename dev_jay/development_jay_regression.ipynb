{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\Miniconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#starting with their imports\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#my imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then next few cells is how they bring in their data:\n",
    "\n",
    "# ROOT_DIR - root directory\n",
    "ROOT_DIR = os.getcwd()+'/'\n",
    "\n",
    "# FEATURE_DIR - directory where feature dataframes are saved\n",
    "DATA_DIR = ROOT_DIR + 'dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of peptides: 45206\n"
     ]
    }
   ],
   "source": [
    "#load their data\n",
    "DF_prest = pd.concat([pd.read_csv(DATA_DIR+'DF_prest_features_1.csv',index_col=0),\n",
    "                      pd.read_csv(DATA_DIR+'DF_prest_features_2.csv',index_col=0),\n",
    "                      pd.read_csv(DATA_DIR+'DF_prest_features_3.csv',index_col=0),\n",
    "                      pd.read_csv(DATA_DIR+'DF_prest_features_4.csv',index_col=0)])\n",
    "print ('Number of peptides:', len(DF_prest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prest_id</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>conc_cf</th>\n",
       "      <th>aa_seq</th>\n",
       "      <th>nt_seq</th>\n",
       "      <th>aa_len</th>\n",
       "      <th>true_nt_seq</th>\n",
       "      <th>AAA</th>\n",
       "      <th>AAT</th>\n",
       "      <th>AAC</th>\n",
       "      <th>...</th>\n",
       "      <th>disembl_HOTLOOPS_frac</th>\n",
       "      <th>ronn_avg</th>\n",
       "      <th>ronn_results</th>\n",
       "      <th>ronn_frac</th>\n",
       "      <th>disopred_results</th>\n",
       "      <th>disopred_avg</th>\n",
       "      <th>disopred_pb_results</th>\n",
       "      <th>disopred_pb_avg</th>\n",
       "      <th>disopred_frac</th>\n",
       "      <th>disopred_pb_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140095</td>\n",
       "      <td>G3V3N0</td>\n",
       "      <td>4.3075</td>\n",
       "      <td>IMTAPSSFEQFKVAMNYLQLYNVPDCLEDIQDADCSSSKCSSSASS...</td>\n",
       "      <td>GACAAGCTTGCGGCCGCAATTATGACAGCTCCCTCCAGTTTTGAGC...</td>\n",
       "      <td>139</td>\n",
       "      <td>ATTATGACAGCTCCCTCCAGTTTTGAGCAGTTTAAAGTGGCAATGA...</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>0.495827</td>\n",
       "      <td>imtapssfeqfkvamnylqlynvpdclediqDADCSSSKCSSSASS...</td>\n",
       "      <td>0.482014</td>\n",
       "      <td>ImtapssfeqfkvamnylqlynvpdclediqdadcsSSKCSSSASS...</td>\n",
       "      <td>0.38705</td>\n",
       "      <td>-...................................^^^^^^^^^^...</td>\n",
       "      <td>0.31777</td>\n",
       "      <td>0.388489</td>\n",
       "      <td>0.359712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   prest_id uniprot_id  conc_cf  \\\n",
       "0    140095     G3V3N0   4.3075   \n",
       "\n",
       "                                              aa_seq  \\\n",
       "0  IMTAPSSFEQFKVAMNYLQLYNVPDCLEDIQDADCSSSKCSSSASS...   \n",
       "\n",
       "                                              nt_seq  aa_len  \\\n",
       "0  GACAAGCTTGCGGCCGCAATTATGACAGCTCCCTCCAGTTTTGAGC...     139   \n",
       "\n",
       "                                         true_nt_seq       AAA       AAT  \\\n",
       "0  ATTATGACAGCTCCCTCCAGTTTTGAGCAGTTTAAAGTGGCAATGA...  0.057554  0.043165   \n",
       "\n",
       "        AAC        ...         disembl_HOTLOOPS_frac  ronn_avg  \\\n",
       "0  0.021583        ...                      0.410072  0.495827   \n",
       "\n",
       "                                        ronn_results  ronn_frac  \\\n",
       "0  imtapssfeqfkvamnylqlynvpdclediqDADCSSSKCSSSASS...   0.482014   \n",
       "\n",
       "                                    disopred_results  disopred_avg  \\\n",
       "0  ImtapssfeqfkvamnylqlynvpdclediqdadcsSSKCSSSASS...       0.38705   \n",
       "\n",
       "                                 disopred_pb_results  disopred_pb_avg  \\\n",
       "0  -...................................^^^^^^^^^^...          0.31777   \n",
       "\n",
       "   disopred_frac  disopred_pb_frac  \n",
       "0       0.388489          0.359712  \n",
       "\n",
       "[1 rows x 163 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_prest.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_features = ['list_comp_A','list_comp_R','list_comp_N',\n",
    "               'list_comp_D','list_comp_C','list_comp_Q','list_comp_E','list_comp_G',\n",
    "               'list_comp_H','list_comp_I','list_comp_L','list_comp_K','list_comp_M',\n",
    "               'list_comp_F','list_comp_P','list_comp_S','list_comp_T','list_comp_W',\n",
    "               'list_comp_Y','list_comp_V',\n",
    "               # Amino acid types\n",
    "               'frac_aliphatic', 'frac_uncharged_polar', 'frac_polar',\n",
    "               'frac_hydrophobic', 'frac_positive', 'frac_sulfur', 'frac_negative', 'frac_amide',\n",
    "               'frac_alcohol']\n",
    "\n",
    "disorder_features = ['disembl_COILS_frac','disembl_REM465_frac','disembl_HOTLOOPS_frac','ronn_avg','ronn_frac',\n",
    "                    'disopred_avg','disopred_pb_avg','disopred_frac','disopred_pb_frac']\n",
    "\n",
    "                    \n",
    "phys_features = ['aa_len',                                        \n",
    "                # Physical properties\n",
    "                 'bio_pI','bio_mW','bio_aromaticity','bio_instability','bio_gravy','abs_avg_charge','abs_charge',\n",
    "                 'avg_charge']\n",
    "                    \n",
    "rna_features = ['AAA','AAC','AAT','AAG','ACA','ACC','ACT','ACG','ATA','ATC','ATT','ATG','AGA','AGC','AGT',\n",
    "                'AGG','CAA','CAC','CAT','CAG','CCA','CCC','CCT','CCG','CTA','CTC','CTT','CTG','CGA','CGC',\n",
    "                'CGT','CGG','TAA','TAC','TAT','TAG','TCA','TCC','TCT','TCG','TTA','TTC','TTT','TTG','TGA',\n",
    "                'TGC','TGT','TGG','GAA','GAC','GAT','GAG','GCA','GCC','GCT','GCG','GTA','GTC','GTT','GTG',\n",
    "                'GGA','GGC','GGT','GGG',\n",
    "                'GC_content','list_nuc_A','list_nuc_C','list_nuc_G','list_nuc_T',\n",
    "                'GC30',\n",
    "                # SD sequences\n",
    "                'sd_like_fwd','sd_like_fwd_frac','sd_like_rev','sd_like_rev_frac','sd_seq_fwd',\n",
    "                'sd_seq_fwd_frac','sd_seq_rev','sd_seq_rev_frac',\n",
    "                # RNA folding\n",
    "                'RNA_folding_energy','RNA_40_energy','tAI']\n",
    "                    \n",
    "ss_features = ['acc20_mean','ss_helix', 'ss_ext', 'ss_c', 'ss8_helix', 'ss8_ext', 'ss8_turn', 'ss8_helix3',\n",
    "               'ss8_pi_helix', 'ss8_bridge', 'ss8_bend', 'ss8_coil', 'acc_frac',\n",
    "               'in_gravy','out_gravy', 'acc_hydrophilic_in','acc_hydrophilic_out',\n",
    "               'acc_hydrophobic_in','acc_hydrophobic_out']\n",
    "\n",
    "list_of_features = aa_features+disorder_features+phys_features+rna_features+ss_features\n",
    "\n",
    "#changed this part of their code so I bring in all of the data instead of just the to and bottom 25%\n",
    "DF_prest_features = DF_prest[list_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_comp_A</th>\n",
       "      <th>list_comp_R</th>\n",
       "      <th>list_comp_N</th>\n",
       "      <th>list_comp_D</th>\n",
       "      <th>list_comp_C</th>\n",
       "      <th>list_comp_Q</th>\n",
       "      <th>list_comp_E</th>\n",
       "      <th>list_comp_G</th>\n",
       "      <th>list_comp_H</th>\n",
       "      <th>list_comp_I</th>\n",
       "      <th>...</th>\n",
       "      <th>ss8_bridge</th>\n",
       "      <th>ss8_bend</th>\n",
       "      <th>ss8_coil</th>\n",
       "      <th>acc_frac</th>\n",
       "      <th>in_gravy</th>\n",
       "      <th>out_gravy</th>\n",
       "      <th>acc_hydrophilic_in</th>\n",
       "      <th>acc_hydrophilic_out</th>\n",
       "      <th>acc_hydrophobic_in</th>\n",
       "      <th>acc_hydrophobic_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.064748</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.071942</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.546763</td>\n",
       "      <td>0.625899</td>\n",
       "      <td>0.599281</td>\n",
       "      <td>-1.199281</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.438849</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.115108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.423611</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.378472</td>\n",
       "      <td>-0.747917</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.215278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.360294</td>\n",
       "      <td>-0.994853</td>\n",
       "      <td>0.066176</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.056911</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.430894</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.312195</td>\n",
       "      <td>-1.328455</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>0.162602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.395161</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>-1.391129</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.379032</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   list_comp_A  list_comp_R  list_comp_N  list_comp_D  list_comp_C  \\\n",
       "0     0.057554     0.057554     0.064748     0.057554     0.050360   \n",
       "1     0.111111     0.069444     0.027778     0.000000     0.027778   \n",
       "2     0.066176     0.139706     0.110294     0.044118     0.058824   \n",
       "3     0.089431     0.056911     0.097561     0.073171     0.024390   \n",
       "4     0.072581     0.072581     0.016129     0.000000     0.072581   \n",
       "\n",
       "   list_comp_Q  list_comp_E  list_comp_G  list_comp_H  list_comp_I  \\\n",
       "0     0.035971     0.071942     0.043165     0.007194     0.021583   \n",
       "1     0.020833     0.118056     0.076389     0.013889     0.020833   \n",
       "2     0.044118     0.000000     0.022059     0.044118     0.051471   \n",
       "3     0.056911     0.065041     0.048780     0.008130     0.008130   \n",
       "4     0.080645     0.080645     0.064516     0.056452     0.024194   \n",
       "\n",
       "          ...           ss8_bridge  ss8_bend  ss8_coil  acc_frac  in_gravy  \\\n",
       "0         ...             0.000000  0.014388  0.546763  0.625899  0.599281   \n",
       "1         ...             0.000000  0.013889  0.423611  0.638889  0.378472   \n",
       "2         ...             0.022059  0.117647  0.235294  0.588235  0.360294   \n",
       "3         ...             0.000000  0.008130  0.430894  0.674797  0.312195   \n",
       "4         ...             0.000000  0.008065  0.395161  0.685484  0.572581   \n",
       "\n",
       "   out_gravy  acc_hydrophilic_in  acc_hydrophilic_out  acc_hydrophobic_in  \\\n",
       "0  -1.199281            0.057554             0.438849            0.294964   \n",
       "1  -0.747917            0.069444             0.291667            0.263889   \n",
       "2  -0.994853            0.066176             0.323529            0.323529   \n",
       "3  -1.328455            0.073171             0.439024            0.235772   \n",
       "4  -1.391129            0.048387             0.379032            0.258065   \n",
       "\n",
       "   acc_hydrophobic_out  \n",
       "0             0.115108  \n",
       "1             0.215278  \n",
       "2             0.176471  \n",
       "3             0.162602  \n",
       "4             0.193548  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_of_features))\n",
    "DF_prest_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the top predictors from the paper\n",
    "top_ten = ['bio_pI', #Grand avg hydropathy\n",
    "          'list_comp_L', 'avg_charge', 'frac_polar', 'ss8_ext', 'acc_hydrophobic_in', #extended secondary structure (3-letter)\n",
    "          'list_comp_Y'] #Average GRAVY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conc_cf</th>\n",
       "      <th>bio_pI</th>\n",
       "      <th>list_comp_L</th>\n",
       "      <th>avg_charge</th>\n",
       "      <th>frac_polar</th>\n",
       "      <th>ss8_ext</th>\n",
       "      <th>acc_hydrophobic_in</th>\n",
       "      <th>list_comp_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.3075</td>\n",
       "      <td>5.446350</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>-0.014388</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>0.294964</td>\n",
       "      <td>0.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9154</td>\n",
       "      <td>6.678894</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4877</td>\n",
       "      <td>10.720642</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.308824</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7224</td>\n",
       "      <td>8.979797</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.235772</td>\n",
       "      <td>0.032520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.3848</td>\n",
       "      <td>9.234802</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conc_cf     bio_pI  list_comp_L  avg_charge  frac_polar   ss8_ext  \\\n",
       "0   4.3075   5.446350     0.050360   -0.014388    0.410072  0.115108   \n",
       "1   2.9154   6.678894     0.111111    0.000000    0.291667  0.013889   \n",
       "2   1.4877  10.720642     0.058824    0.102941    0.411765  0.308824   \n",
       "3   6.7224   8.979797     0.073171    0.032520    0.341463  0.341463   \n",
       "4   3.3848   9.234802     0.056452    0.064516    0.451613  0.080645   \n",
       "\n",
       "   acc_hydrophobic_in  list_comp_Y  \n",
       "0            0.294964     0.021583  \n",
       "1            0.263889     0.041667  \n",
       "2            0.323529     0.029412  \n",
       "3            0.235772     0.032520  \n",
       "4            0.258065     0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the predictors and the concentrations so I can down sample the data\n",
    "df = pd.concat([DF_prest['conc_cf'], DF_prest_features[top_ten]], axis=1 )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#down sample the dataset so training can go faster\n",
    "df = df.sample(frac=0.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape= (2260, 7)\n",
      "y.shape= (2260,)\n"
     ]
    }
   ],
   "source": [
    "#Move predictors to X and values to y\n",
    "X = df[top_ten]\n",
    "y = df['conc_cf']\n",
    "print('X.shape=', X.shape)\n",
    "print('y.shape=', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape= (1514, 7)\n",
      "y_train.shape= (1514,)\n"
     ]
    }
   ],
   "source": [
    "#Make a test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=27315)\n",
    "print('X_train.shape=', X_train.shape)\n",
    "print('y_train.shape=', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1514 samples, validate on 746 samples\n",
      "Epoch 1/100\n",
      "1514/1514 [==============================] - 0s 316us/step - loss: 13.6111 - acc: 6.6050e-04 - val_loss: 9.0974 - val_acc: 0.0013\n",
      "Epoch 2/100\n",
      "1514/1514 [==============================] - 0s 66us/step - loss: 8.7315 - acc: 0.0000e+00 - val_loss: 8.8008 - val_acc: 0.0013\n",
      "Epoch 3/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 8.4032 - acc: 0.0000e+00 - val_loss: 8.3825 - val_acc: 0.0013\n",
      "Epoch 4/100\n",
      "1514/1514 [==============================] - 0s 129us/step - loss: 8.1118 - acc: 0.0000e+00 - val_loss: 8.2840 - val_acc: 0.0013\n",
      "Epoch 5/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 8.0312 - acc: 0.0000e+00 - val_loss: 8.6064 - val_acc: 0.0013\n",
      "Epoch 6/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 8.0251 - acc: 0.0000e+00 - val_loss: 8.3440 - val_acc: 0.0013\n",
      "Epoch 7/100\n",
      "1514/1514 [==============================] - 0s 85us/step - loss: 7.9421 - acc: 0.0000e+00 - val_loss: 8.1195 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1514/1514 [==============================] - 0s 66us/step - loss: 7.9197 - acc: 0.0000e+00 - val_loss: 8.5664 - val_acc: 0.0013\n",
      "Epoch 9/100\n",
      "1514/1514 [==============================] - 0s 91us/step - loss: 7.8970 - acc: 0.0000e+00 - val_loss: 8.2736 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.8669 - acc: 0.0000e+00 - val_loss: 8.1282 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.9163 - acc: 0.0000e+00 - val_loss: 8.2326 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.8516 - acc: 0.0000e+00 - val_loss: 7.9877 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1514/1514 [==============================] - 0s 68us/step - loss: 7.8689 - acc: 0.0000e+00 - val_loss: 8.0401 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1514/1514 [==============================] - 0s 66us/step - loss: 7.8789 - acc: 0.0000e+00 - val_loss: 8.0568 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1514/1514 [==============================] - 0s 77us/step - loss: 7.8165 - acc: 0.0000e+00 - val_loss: 7.9283 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.9108 - acc: 0.0000e+00 - val_loss: 7.9420 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.8193 - acc: 0.0000e+00 - val_loss: 8.0084 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1514/1514 [==============================] - 0s 76us/step - loss: 7.8232 - acc: 0.0000e+00 - val_loss: 7.9531 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1514/1514 [==============================] - 0s 66us/step - loss: 7.7843 - acc: 0.0000e+00 - val_loss: 8.0663 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.8174 - acc: 0.0000e+00 - val_loss: 8.1043 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1514/1514 [==============================] - 0s 83us/step - loss: 7.7661 - acc: 6.6050e-04 - val_loss: 7.8727 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.8066 - acc: 0.0000e+00 - val_loss: 7.9026 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.8039 - acc: 0.0000e+00 - val_loss: 8.1279 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1514/1514 [==============================] - 0s 75us/step - loss: 7.7382 - acc: 6.6050e-04 - val_loss: 7.8363 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.8063 - acc: 0.0000e+00 - val_loss: 7.8504 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.8079 - acc: 0.0000e+00 - val_loss: 7.8754 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7483 - acc: 0.0000e+00 - val_loss: 7.8271 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1514/1514 [==============================] - 0s 112us/step - loss: 7.7565 - acc: 0.0000e+00 - val_loss: 7.8551 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1514/1514 [==============================] - 0s 68us/step - loss: 7.7437 - acc: 0.0000e+00 - val_loss: 7.8105 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7768 - acc: 0.0000e+00 - val_loss: 8.3395 - val_acc: 0.0013\n",
      "Epoch 31/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7778 - acc: 0.0000e+00 - val_loss: 8.0647 - val_acc: 0.0013\n",
      "Epoch 32/100\n",
      "1514/1514 [==============================] - 0s 67us/step - loss: 7.7636 - acc: 6.6050e-04 - val_loss: 7.8753 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7480 - acc: 0.0000e+00 - val_loss: 8.1446 - val_acc: 0.0013\n",
      "Epoch 34/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7827 - acc: 0.0000e+00 - val_loss: 7.8803 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7184 - acc: 0.0000e+00 - val_loss: 8.4827 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7933 - acc: 0.0000e+00 - val_loss: 7.9286 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1514/1514 [==============================] - 0s 60us/step - loss: 7.7464 - acc: 0.0000e+00 - val_loss: 7.8070 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7305 - acc: 6.6050e-04 - val_loss: 7.8119 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7191 - acc: 0.0000e+00 - val_loss: 8.1617 - val_acc: 0.0013\n",
      "Epoch 40/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7158 - acc: 6.6050e-04 - val_loss: 8.1009 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1514/1514 [==============================] - 0s 65us/step - loss: 7.7798 - acc: 0.0000e+00 - val_loss: 7.8033 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7019 - acc: 0.0000e+00 - val_loss: 7.8965 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1514/1514 [==============================] - 0s 71us/step - loss: 7.7311 - acc: 0.0000e+00 - val_loss: 8.1737 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1514/1514 [==============================] - 0s 50us/step - loss: 7.7404 - acc: 0.0000e+00 - val_loss: 7.8224 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7420 - acc: 6.6050e-04 - val_loss: 7.9056 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1514/1514 [==============================] - 0s 58us/step - loss: 7.7833 - acc: 0.0000e+00 - val_loss: 8.1735 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1514/1514 [==============================] - 0s 70us/step - loss: 7.7246 - acc: 0.0000e+00 - val_loss: 7.8012 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1514/1514 [==============================] - 0s 58us/step - loss: 7.7359 - acc: 0.0000e+00 - val_loss: 7.7974 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7325 - acc: 0.0000e+00 - val_loss: 7.8308 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7473 - acc: 0.0000e+00 - val_loss: 7.9510 - val_acc: 0.0013\n",
      "Epoch 51/100\n",
      "1514/1514 [==============================] - 0s 79us/step - loss: 7.7317 - acc: 0.0000e+00 - val_loss: 7.7968 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7219 - acc: 0.0000e+00 - val_loss: 7.8316 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7178 - acc: 0.0000e+00 - val_loss: 7.8868 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7410 - acc: 0.0000e+00 - val_loss: 7.8001 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7802 - acc: 0.0000e+00 - val_loss: 8.1290 - val_acc: 0.0013\n",
      "Epoch 56/100\n",
      "1514/1514 [==============================] - 0s 72us/step - loss: 7.7083 - acc: 0.0000e+00 - val_loss: 7.8860 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514/1514 [==============================] - 0s 69us/step - loss: 7.7190 - acc: 0.0000e+00 - val_loss: 7.9985 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1514/1514 [==============================] - 0s 46us/step - loss: 7.7326 - acc: 0.0000e+00 - val_loss: 7.8156 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7266 - acc: 0.0000e+00 - val_loss: 7.8090 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1514/1514 [==============================] - 0s 55us/step - loss: 7.7205 - acc: 0.0000e+00 - val_loss: 7.9961 - val_acc: 0.0013\n",
      "Epoch 61/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7407 - acc: 0.0000e+00 - val_loss: 7.8178 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7099 - acc: 6.6050e-04 - val_loss: 8.2722 - val_acc: 0.0013\n",
      "Epoch 63/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7263 - acc: 0.0000e+00 - val_loss: 7.8100 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1514/1514 [==============================] - 0s 59us/step - loss: 7.7309 - acc: 0.0000e+00 - val_loss: 7.7951 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1514/1514 [==============================] - 0s 114us/step - loss: 7.7031 - acc: 0.0000e+00 - val_loss: 7.7960 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1514/1514 [==============================] - 0s 98us/step - loss: 7.6854 - acc: 0.0000e+00 - val_loss: 7.8214 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1514/1514 [==============================] - 0s 67us/step - loss: 7.7471 - acc: 0.0000e+00 - val_loss: 7.8051 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1514/1514 [==============================] - 0s 40us/step - loss: 7.7308 - acc: 0.0000e+00 - val_loss: 7.7981 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7439 - acc: 0.0000e+00 - val_loss: 7.7988 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7507 - acc: 0.0000e+00 - val_loss: 7.9127 - val_acc: 0.0013\n",
      "Epoch 71/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7457 - acc: 0.0000e+00 - val_loss: 8.3448 - val_acc: 0.0013\n",
      "Epoch 72/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7474 - acc: 0.0000e+00 - val_loss: 8.0216 - val_acc: 0.0013\n",
      "Epoch 73/100\n",
      "1514/1514 [==============================] - 0s 50us/step - loss: 7.7029 - acc: 0.0000e+00 - val_loss: 7.8006 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7082 - acc: 0.0000e+00 - val_loss: 8.0121 - val_acc: 0.0013\n",
      "Epoch 75/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7128 - acc: 0.0000e+00 - val_loss: 7.8262 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.7017 - acc: 0.0000e+00 - val_loss: 7.9180 - val_acc: 0.0013\n",
      "Epoch 77/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7822 - acc: 0.0000e+00 - val_loss: 7.8131 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.6954 - acc: 0.0000e+00 - val_loss: 7.9768 - val_acc: 0.0013\n",
      "Epoch 79/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7334 - acc: 0.0000e+00 - val_loss: 7.8103 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1514/1514 [==============================] - 0s 65us/step - loss: 7.7055 - acc: 0.0000e+00 - val_loss: 7.8817 - val_acc: 0.0013\n",
      "Epoch 81/100\n",
      "1514/1514 [==============================] - 0s 43us/step - loss: 7.7296 - acc: 0.0000e+00 - val_loss: 7.8378 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7107 - acc: 0.0000e+00 - val_loss: 7.8473 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.6781 - acc: 0.0000e+00 - val_loss: 8.0379 - val_acc: 0.0013\n",
      "Epoch 84/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7022 - acc: 0.0000e+00 - val_loss: 7.8062 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7146 - acc: 0.0000e+00 - val_loss: 8.0551 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7220 - acc: 0.0000e+00 - val_loss: 8.1837 - val_acc: 0.0013\n",
      "Epoch 87/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7483 - acc: 0.0000e+00 - val_loss: 7.8129 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7165 - acc: 0.0000e+00 - val_loss: 7.8046 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1514/1514 [==============================] - 0s 44us/step - loss: 7.7015 - acc: 6.6050e-04 - val_loss: 7.8371 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.7329 - acc: 0.0000e+00 - val_loss: 7.7975 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1514/1514 [==============================] - 0s 41us/step - loss: 7.7170 - acc: 0.0000e+00 - val_loss: 8.2573 - val_acc: 0.0013\n",
      "Epoch 92/100\n",
      "1514/1514 [==============================] - 0s 52us/step - loss: 7.6959 - acc: 6.6050e-04 - val_loss: 7.8015 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1514/1514 [==============================] - 0s 62us/step - loss: 7.6808 - acc: 0.0000e+00 - val_loss: 7.8973 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1514/1514 [==============================] - 0s 109us/step - loss: 7.6938 - acc: 0.0000e+00 - val_loss: 7.8089 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1514/1514 [==============================] - 0s 144us/step - loss: 7.6842 - acc: 0.0000e+00 - val_loss: 7.7978 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1514/1514 [==============================] - 0s 150us/step - loss: 7.6826 - acc: 6.6050e-04 - val_loss: 7.8851 - val_acc: 0.0013\n",
      "Epoch 97/100\n",
      "1514/1514 [==============================] - 0s 136us/step - loss: 7.6829 - acc: 0.0000e+00 - val_loss: 7.7905 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1514/1514 [==============================] - 0s 90us/step - loss: 7.7010 - acc: 0.0000e+00 - val_loss: 7.7909 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1514/1514 [==============================] - 0s 100us/step - loss: 7.7118 - acc: 0.0013 - val_loss: 7.8839 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1514/1514 [==============================] - 0s 73us/step - loss: 7.7180 - acc: 6.6050e-04 - val_loss: 7.8017 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2126def9860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initilize the model\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='selu'))\n",
    "model.add(Dense(24, activation='selu'))\n",
    "model.add(Dense(12, activation='selu'))\n",
    "model.add(Dense(1))\n",
    "#model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss = keras.losses.mean_squared_error, #loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['acc'])\n",
    "\n",
    "#fit the model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Parity Plot')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2126de530f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Parity plot\n",
    "ax_min = -5\n",
    "ax_max = 20\n",
    "\n",
    "plt.scatter(y_test, pred)\n",
    "\n",
    "plt.plot([ax_min, ax_max], [ax_min, ax_max], color='k', \n",
    "         label = 'Perfect Prediction', linewidth=3)\n",
    "\n",
    "\n",
    "plt.ylim(ax_min, ax_max)\n",
    "plt.xlim(ax_min, ax_max)\n",
    "plt.xlabel('True conc.', fontsize=26)\n",
    "plt.ylabel('Predicted conc.', fontsize=26)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title('Parity Plot', fontsize = 16, weight='bold')\n",
    "#plt.legend(fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
