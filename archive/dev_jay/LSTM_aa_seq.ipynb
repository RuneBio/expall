{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape (45206, 6)\n",
      "Processed Data Shape:  (22364, 8)\n"
     ]
    }
   ],
   "source": [
    "# read original data from \n",
    "data = pd.read_csv('../dataframes/DF_prest.csv', index_col=0)\n",
    "print('Original Data Shape', data.shape)\n",
    "# setup 'docs' for use with Tokenizer\n",
    "def nt_seq_doc(nt_sequence):\n",
    "    \"\"\"This function takes in a nucleotide sequence (nt sequence) and adds spaces between each codons.\n",
    "        It also checks that the sequence is divisible by 3 and that it starts with the expected starting sequence\"\"\"\n",
    "    \n",
    "    if 'GACAAGCTTGCGGCCGCA' not in nt_sequence:\n",
    "        return None\n",
    "    true_nt = nt_sequence.split('GACAAGCTTGCGGCCGCA')[1]\n",
    "    if len(true_nt) % 3 != 0:\n",
    "        return None\n",
    "    return ' '.join([true_nt[i:i+3] \n",
    "                     for i in range(0, len(true_nt), 3)])\n",
    "# split quantiles\n",
    "def assign_class(conc):\n",
    "    if conc <= low_cut:\n",
    "        return 0\n",
    "    elif conc >= high_cut:\n",
    "        return 1\n",
    "    return\n",
    "\n",
    "data['nt_seq_doc'] = data['nt_seq'].apply(nt_seq_doc)\n",
    "data = data[pd.notnull(data['nt_seq_doc'])]\n",
    "\n",
    "# identify high and low classes by conc_cf quantiles\n",
    "low_cut = data['conc_cf'].quantile(0.25)\n",
    "high_cut = data['conc_cf'].quantile(0.75)\n",
    "\n",
    "data['class'] = data['conc_cf'].apply(assign_class)\n",
    "#Remove entries that are not assigned a class (remove middle quantiles)\n",
    "data = data[pd.notnull(data['class'])]\n",
    "# check shape\n",
    "print('Processed Data Shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_seq_doc(aa_sequence):\n",
    "    \"\"\"This function takes in an amino acid sequence (aa sequence) and adds spaces between each amino acid.\"\"\"\n",
    "    \n",
    "    return ' '.join([aa_sequence[i:i+1] \n",
    "                     for i in range(0, len(aa_sequence))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T Y Y A W K H E L L G S G T C P A L P P R E V L G M E E L E K L P E E Q V A E E E L E C S A L A V S S P G M V L M Q R A K L Y L E H C I S L N T L V P Y R C F K R R F P G I S R S T Y Y N W R R K A L R R N P S F K P A P A L S A A G T P Q L A S V G E G A V I P W K S E A E E G A G N A T G E'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_seq_doc(data['aa_seq'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aa_seq_doc'] = data['aa_seq'].apply(aa_seq_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'A',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'A',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'A',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'T',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'T',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'T',\n",
       " 'A',\n",
       " ' ',\n",
       " 'A',\n",
       " 'T',\n",
       " 'T',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'T',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'G',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'G',\n",
       " ' ',\n",
       " 'A',\n",
       " 'A',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'T',\n",
       " ' ',\n",
       " 'G',\n",
       " 'A',\n",
       " 'G',\n",
       " ' ',\n",
       " 'T',\n",
       " 'A',\n",
       " 'A',\n",
       " ' ',\n",
       " 'G',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'G',\n",
       " 'C',\n",
       " 'G',\n",
       " ' ',\n",
       " 'C',\n",
       " 'C',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'A',\n",
       " 'C',\n",
       " ' ',\n",
       " 'C',\n",
       " 'G',\n",
       " 'C',\n",
       " ' ',\n",
       " 'T',\n",
       " 'G',\n",
       " 'A']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nt_seq_doc(data['nt_seq'][1])) #is this what the Tokenizer expects? Ask Josh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sequence documents\n",
    "docs = list(data['aa_seq_doc'])\n",
    "# create the tokenizer\n",
    "t = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "# integer encode documents\n",
    "X = t.texts_to_sequences(docs)\n",
    "y = data['class'].values\n",
    "\n",
    "# create test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = len(t.word_index) + 1\n",
    "\n",
    "# truncate and pad input sequences\n",
    "seq_lengths = [len(seq) for seq in X]\n",
    "max_seq_length = max(seq_lengths)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_seq_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed codons, learn w/ single Long Short Term Memory Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 dimensional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 149, 4)            84        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               42000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 42,185\n",
      "Trainable params: 42,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "15654/15654 [==============================] - 107s 7ms/step - loss: 0.6933 - acc: 0.5211\n",
      "Epoch 2/3\n",
      "15654/15654 [==============================] - 106s 7ms/step - loss: 0.6703 - acc: 0.5973\n",
      "Epoch 3/3\n",
      "15654/15654 [==============================] - 107s 7ms/step - loss: 0.6495 - acc: 0.6273\n",
      "Accuracy: 62.62%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 4\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_seq_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 dimensional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 149, 8)            168       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               43600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 43,869\n",
      "Trainable params: 43,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "15654/15654 [==============================] - 107s 7ms/step - loss: 0.6864 - acc: 0.5418\n",
      "Epoch 2/3\n",
      "15654/15654 [==============================] - 106s 7ms/step - loss: 0.6619 - acc: 0.6056\n",
      "Epoch 3/3\n",
      "15654/15654 [==============================] - 106s 7ms/step - loss: 0.6482 - acc: 0.6277\n",
      "Accuracy: 62.97%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_seq_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 dimensional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 149, 16)           336       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               46800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 47,237\n",
      "Trainable params: 47,237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "15654/15654 [==============================] - 111s 7ms/step - loss: 0.6812 - acc: 0.5611\n",
      "Epoch 2/3\n",
      "15654/15654 [==============================] - 110s 7ms/step - loss: 0.6439 - acc: 0.6286\n",
      "Epoch 3/3\n",
      "15654/15654 [==============================] - 111s 7ms/step - loss: 0.6351 - acc: 0.6421\n",
      "Accuracy: 63.77%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 16\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_seq_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32 dimensional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 149, 32)           672       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 53,973\n",
      "Trainable params: 53,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "15654/15654 [==============================] - 119s 8ms/step - loss: 0.6807 - acc: 0.5616\n",
      "Epoch 2/3\n",
      "15654/15654 [==============================] - 119s 8ms/step - loss: 0.6464 - acc: 0.6315\n",
      "Epoch 3/3\n",
      "15654/15654 [==============================] - 118s 8ms/step - loss: 0.6363 - acc: 0.6418\n",
      "Accuracy: 64.08%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_seq_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=100)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hook LSTM to basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 149, 16)           336       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 149, 128)          6272      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               91600     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 98,309\n",
      "Trainable params: 98,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 15654 samples, validate on 6710 samples\n",
      "Epoch 1/15\n",
      "15654/15654 [==============================] - 132s 8ms/step - loss: 0.6655 - acc: 0.5850 - val_loss: 0.6543 - val_acc: 0.6294\n",
      "Epoch 2/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.6367 - acc: 0.6394 - val_loss: 0.6450 - val_acc: 0.6249\n",
      "Epoch 3/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.6276 - acc: 0.6547 - val_loss: 0.6303 - val_acc: 0.6537\n",
      "Epoch 4/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.6216 - acc: 0.6609 - val_loss: 0.6230 - val_acc: 0.6538\n",
      "Epoch 5/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.6063 - acc: 0.6736 - val_loss: 0.6070 - val_acc: 0.6724\n",
      "Epoch 6/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.5880 - acc: 0.6899 - val_loss: 0.5811 - val_acc: 0.6924\n",
      "Epoch 7/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.5609 - acc: 0.7117 - val_loss: 0.5703 - val_acc: 0.7067\n",
      "Epoch 8/15\n",
      "15654/15654 [==============================] - 132s 8ms/step - loss: 0.5412 - acc: 0.7289 - val_loss: 0.5696 - val_acc: 0.7158\n",
      "Epoch 9/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.5302 - acc: 0.7366 - val_loss: 0.5625 - val_acc: 0.7148\n",
      "Epoch 10/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.5181 - acc: 0.7415 - val_loss: 0.5482 - val_acc: 0.7246\n",
      "Epoch 11/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.5043 - acc: 0.7567 - val_loss: 0.5518 - val_acc: 0.7204\n",
      "Epoch 12/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.4942 - acc: 0.7615 - val_loss: 0.5455 - val_acc: 0.7338\n",
      "Epoch 13/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.4834 - acc: 0.7672 - val_loss: 0.5460 - val_acc: 0.7262\n",
      "Epoch 14/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.4724 - acc: 0.7749 - val_loss: 0.5466 - val_acc: 0.7316\n",
      "Epoch 15/15\n",
      "15654/15654 [==============================] - 131s 8ms/step - loss: 0.4603 - acc: 0.7842 - val_loss: 0.5602 - val_acc: 0.7325\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# create the model\n",
    "embedding_vecor_length = 16\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_seq_length))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='selu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# record training progress\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=64,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# plot loss vs. epoch\n",
    "# https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
