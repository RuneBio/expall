{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# stuck with the CPU version for now...\n",
    "high_exp = pd.read_csv(\"high_exp.csv\", index_col=0)\n",
    "low_exp = pd.read_csv(\"low_exp.csv\", index_col=0)\n",
    "\n",
    "data_df = pd.concat([high_exp, low_exp], axis=0)\n",
    "\n",
    "def string_to_matrix(color_string):\n",
    "    color_string = str(color_string)\n",
    "    list_of_strings = color_string.replace('[', '').replace(']', '').split('\\n')\n",
    "    list_of_lists = [channels.strip().split() \n",
    "                     for channels in list_of_strings\n",
    "                     if 'nan' not in list_of_strings\n",
    "                    ]\n",
    "    remaining_pad = 181 - len(list_of_lists)\n",
    "    while remaining_pad > 0:\n",
    "        list_of_lists.append(list([0, 0, 0, 0]))\n",
    "        remaining_pad = remaining_pad - 1\n",
    "    \n",
    "    return np.array(list_of_lists).astype(np.float)\n",
    "\n",
    "data_df['color_matrix'] = data_df['color_matrix'].apply(string_to_matrix)\n",
    "\n",
    "# create train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.zeros((22604, 181, 4))\n",
    "for idx, colors in enumerate(data_df['color_matrix'].values):\n",
    "    X[idx, :, :] = colors\n",
    "    \n",
    "y = data_df['class'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/100\n",
      " - 3s - loss: 0.7092 - acc: 0.5067 - val_loss: 0.6918 - val_acc: 0.5215\n",
      "Epoch 2/100\n",
      " - 2s - loss: 0.6933 - acc: 0.5221 - val_loss: 0.6906 - val_acc: 0.5270\n",
      "Epoch 3/100\n",
      " - 2s - loss: 0.6912 - acc: 0.5267 - val_loss: 0.6897 - val_acc: 0.5385\n",
      "Epoch 4/100\n",
      " - 2s - loss: 0.6911 - acc: 0.5263 - val_loss: 0.6903 - val_acc: 0.5351\n",
      "Epoch 5/100\n",
      " - 2s - loss: 0.6907 - acc: 0.5274 - val_loss: 0.6888 - val_acc: 0.5469\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.6902 - acc: 0.5269 - val_loss: 0.6899 - val_acc: 0.5348\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.6897 - acc: 0.5300 - val_loss: 0.6883 - val_acc: 0.5492\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.6895 - acc: 0.5357 - val_loss: 0.6876 - val_acc: 0.5472\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.6890 - acc: 0.5335 - val_loss: 0.6872 - val_acc: 0.5531\n",
      "Epoch 10/100\n",
      " - 2s - loss: 0.6888 - acc: 0.5336 - val_loss: 0.6871 - val_acc: 0.5515\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.6889 - acc: 0.5401 - val_loss: 0.6869 - val_acc: 0.5537\n",
      "Epoch 12/100\n",
      " - 2s - loss: 0.6886 - acc: 0.5328 - val_loss: 0.6870 - val_acc: 0.5518\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.6879 - acc: 0.5405 - val_loss: 0.6865 - val_acc: 0.5556\n",
      "Epoch 14/100\n",
      " - 2s - loss: 0.6887 - acc: 0.5430 - val_loss: 0.6863 - val_acc: 0.5520\n",
      "Epoch 15/100\n",
      " - 2s - loss: 0.6878 - acc: 0.5434 - val_loss: 0.6857 - val_acc: 0.5575\n",
      "Epoch 16/100\n",
      " - 2s - loss: 0.6880 - acc: 0.5408 - val_loss: 0.6859 - val_acc: 0.5551\n",
      "Epoch 17/100\n",
      " - 2s - loss: 0.6870 - acc: 0.5441 - val_loss: 0.6862 - val_acc: 0.5515\n",
      "Epoch 18/100\n",
      " - 2s - loss: 0.6873 - acc: 0.5437 - val_loss: 0.6853 - val_acc: 0.5590\n",
      "Epoch 19/100\n",
      " - 2s - loss: 0.6863 - acc: 0.5471 - val_loss: 0.6861 - val_acc: 0.5456\n",
      "Epoch 20/100\n",
      " - 2s - loss: 0.6871 - acc: 0.5475 - val_loss: 0.6856 - val_acc: 0.5525\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.6872 - acc: 0.5442 - val_loss: 0.6852 - val_acc: 0.5537\n",
      "Epoch 22/100\n",
      " - 2s - loss: 0.6869 - acc: 0.5437 - val_loss: 0.6845 - val_acc: 0.5599\n",
      "Epoch 23/100\n",
      " - 2s - loss: 0.6866 - acc: 0.5434 - val_loss: 0.6891 - val_acc: 0.5335\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.6866 - acc: 0.5487 - val_loss: 0.6851 - val_acc: 0.5523\n",
      "Epoch 25/100\n",
      " - 2s - loss: 0.6863 - acc: 0.5484 - val_loss: 0.6840 - val_acc: 0.5662\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.6857 - acc: 0.5491 - val_loss: 0.6837 - val_acc: 0.5615\n",
      "Epoch 27/100\n",
      " - 2s - loss: 0.6861 - acc: 0.5491 - val_loss: 0.6837 - val_acc: 0.5656\n",
      "Epoch 28/100\n",
      " - 2s - loss: 0.6847 - acc: 0.5538 - val_loss: 0.6841 - val_acc: 0.5599\n",
      "Epoch 29/100\n",
      " - 2s - loss: 0.6860 - acc: 0.5508 - val_loss: 0.6837 - val_acc: 0.5575\n",
      "Epoch 30/100\n",
      " - 2s - loss: 0.6846 - acc: 0.5515 - val_loss: 0.6860 - val_acc: 0.5475\n",
      "Epoch 31/100\n",
      " - 2s - loss: 0.6856 - acc: 0.5531 - val_loss: 0.6830 - val_acc: 0.5699\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.6852 - acc: 0.5518 - val_loss: 0.6835 - val_acc: 0.5666\n",
      "Epoch 33/100\n",
      " - 2s - loss: 0.6857 - acc: 0.5531 - val_loss: 0.6828 - val_acc: 0.5709\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.6848 - acc: 0.5530 - val_loss: 0.6830 - val_acc: 0.5758\n",
      "Epoch 35/100\n",
      " - 2s - loss: 0.6855 - acc: 0.5538 - val_loss: 0.6843 - val_acc: 0.5568\n",
      "Epoch 36/100\n",
      " - 2s - loss: 0.6839 - acc: 0.5571 - val_loss: 0.6826 - val_acc: 0.5743\n",
      "Epoch 37/100\n",
      " - 2s - loss: 0.6850 - acc: 0.5523 - val_loss: 0.6826 - val_acc: 0.5711\n",
      "Epoch 38/100\n",
      " - 2s - loss: 0.6852 - acc: 0.5494 - val_loss: 0.6823 - val_acc: 0.5736\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.6844 - acc: 0.5592 - val_loss: 0.6842 - val_acc: 0.5574\n",
      "Epoch 40/100\n",
      " - 2s - loss: 0.6843 - acc: 0.5583 - val_loss: 0.6824 - val_acc: 0.5749\n",
      "Epoch 41/100\n",
      " - 2s - loss: 0.6852 - acc: 0.5530 - val_loss: 0.6828 - val_acc: 0.5690\n",
      "Epoch 42/100\n",
      " - 2s - loss: 0.6849 - acc: 0.5538 - val_loss: 0.6829 - val_acc: 0.5640\n",
      "Epoch 43/100\n",
      " - 2s - loss: 0.6843 - acc: 0.5535 - val_loss: 0.6829 - val_acc: 0.5708\n",
      "Epoch 44/100\n",
      " - 2s - loss: 0.6837 - acc: 0.5576 - val_loss: 0.6828 - val_acc: 0.5690\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.6845 - acc: 0.5535 - val_loss: 0.6832 - val_acc: 0.5671\n",
      "Epoch 46/100\n",
      " - 2s - loss: 0.6845 - acc: 0.5535 - val_loss: 0.6829 - val_acc: 0.5693\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.6832 - acc: 0.5573 - val_loss: 0.6831 - val_acc: 0.5646\n",
      "Epoch 48/100\n",
      " - 2s - loss: 0.6844 - acc: 0.5516 - val_loss: 0.6823 - val_acc: 0.5678\n",
      "Epoch 49/100\n",
      " - 2s - loss: 0.6829 - acc: 0.5530 - val_loss: 0.6824 - val_acc: 0.5692\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.6831 - acc: 0.5598 - val_loss: 0.6827 - val_acc: 0.5669\n",
      "Epoch 51/100\n",
      " - 2s - loss: 0.6839 - acc: 0.5591 - val_loss: 0.6821 - val_acc: 0.5677\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.6839 - acc: 0.5538 - val_loss: 0.6831 - val_acc: 0.5687\n",
      "Epoch 53/100\n",
      " - 2s - loss: 0.6815 - acc: 0.5624 - val_loss: 0.6827 - val_acc: 0.5607\n",
      "Epoch 54/100\n",
      " - 2s - loss: 0.6841 - acc: 0.5563 - val_loss: 0.6825 - val_acc: 0.5652\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.6834 - acc: 0.5573 - val_loss: 0.6825 - val_acc: 0.5669\n",
      "Epoch 56/100\n",
      " - 2s - loss: 0.6833 - acc: 0.5576 - val_loss: 0.6828 - val_acc: 0.5684\n",
      "Epoch 57/100\n",
      " - 2s - loss: 0.6832 - acc: 0.5580 - val_loss: 0.6827 - val_acc: 0.5686\n",
      "Epoch 58/100\n",
      " - 2s - loss: 0.6847 - acc: 0.5548 - val_loss: 0.6826 - val_acc: 0.5650\n",
      "Epoch 59/100\n",
      " - 2s - loss: 0.6832 - acc: 0.5584 - val_loss: 0.6837 - val_acc: 0.5563\n",
      "Epoch 60/100\n",
      " - 2s - loss: 0.6828 - acc: 0.5544 - val_loss: 0.6824 - val_acc: 0.5658\n",
      "Epoch 61/100\n",
      " - 2s - loss: 0.6817 - acc: 0.5630 - val_loss: 0.6824 - val_acc: 0.5656\n",
      "Epoch 62/100\n",
      " - 2s - loss: 0.6830 - acc: 0.5594 - val_loss: 0.6823 - val_acc: 0.5656\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.6829 - acc: 0.5567 - val_loss: 0.6823 - val_acc: 0.5659\n",
      "Epoch 64/100\n",
      " - 2s - loss: 0.6826 - acc: 0.5580 - val_loss: 0.6825 - val_acc: 0.5683\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.6827 - acc: 0.5599 - val_loss: 0.6825 - val_acc: 0.5647\n",
      "Epoch 66/100\n",
      " - 2s - loss: 0.6828 - acc: 0.5556 - val_loss: 0.6828 - val_acc: 0.5605\n",
      "Epoch 67/100\n",
      " - 2s - loss: 0.6835 - acc: 0.5586 - val_loss: 0.6821 - val_acc: 0.5677\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.6827 - acc: 0.5564 - val_loss: 0.6826 - val_acc: 0.5621\n",
      "Epoch 69/100\n",
      " - 2s - loss: 0.6822 - acc: 0.5605 - val_loss: 0.6824 - val_acc: 0.5615\n",
      "Epoch 70/100\n",
      " - 2s - loss: 0.6827 - acc: 0.5592 - val_loss: 0.6822 - val_acc: 0.5658\n",
      "Epoch 71/100\n",
      " - 2s - loss: 0.6833 - acc: 0.5584 - val_loss: 0.6820 - val_acc: 0.5699\n",
      "Epoch 72/100\n",
      " - 2s - loss: 0.6820 - acc: 0.5602 - val_loss: 0.6821 - val_acc: 0.5636\n",
      "Epoch 73/100\n",
      " - 2s - loss: 0.6821 - acc: 0.5602 - val_loss: 0.6827 - val_acc: 0.5622\n",
      "Epoch 74/100\n",
      " - 2s - loss: 0.6826 - acc: 0.5577 - val_loss: 0.6820 - val_acc: 0.5653\n",
      "Epoch 75/100\n",
      " - 2s - loss: 0.6819 - acc: 0.5594 - val_loss: 0.6818 - val_acc: 0.5644\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.6824 - acc: 0.5618 - val_loss: 0.6818 - val_acc: 0.5646\n",
      "Epoch 77/100\n",
      " - 2s - loss: 0.6831 - acc: 0.5615 - val_loss: 0.6825 - val_acc: 0.5677\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.6827 - acc: 0.5567 - val_loss: 0.6829 - val_acc: 0.5605\n",
      "Epoch 79/100\n",
      " - 2s - loss: 0.6821 - acc: 0.5608 - val_loss: 0.6821 - val_acc: 0.5680\n",
      "Epoch 80/100\n",
      " - 2s - loss: 0.6831 - acc: 0.5601 - val_loss: 0.6819 - val_acc: 0.5668\n",
      "Epoch 81/100\n",
      " - 2s - loss: 0.6833 - acc: 0.5532 - val_loss: 0.6823 - val_acc: 0.5613\n",
      "Epoch 82/100\n",
      " - 2s - loss: 0.6832 - acc: 0.5575 - val_loss: 0.6819 - val_acc: 0.5661\n",
      "Epoch 83/100\n",
      " - 2s - loss: 0.6834 - acc: 0.5567 - val_loss: 0.6823 - val_acc: 0.5652\n",
      "Epoch 84/100\n",
      " - 2s - loss: 0.6827 - acc: 0.5617 - val_loss: 0.6821 - val_acc: 0.5661\n",
      "Epoch 85/100\n",
      " - 2s - loss: 0.6817 - acc: 0.5600 - val_loss: 0.6821 - val_acc: 0.5675\n",
      "Epoch 86/100\n",
      " - 2s - loss: 0.6826 - acc: 0.5595 - val_loss: 0.6821 - val_acc: 0.5627\n",
      "Epoch 87/100\n",
      " - 2s - loss: 0.6821 - acc: 0.5609 - val_loss: 0.6818 - val_acc: 0.5644\n",
      "Epoch 88/100\n",
      " - 2s - loss: 0.6832 - acc: 0.5547 - val_loss: 0.6817 - val_acc: 0.5658\n",
      "Epoch 89/100\n",
      " - 2s - loss: 0.6830 - acc: 0.5537 - val_loss: 0.6825 - val_acc: 0.5638\n",
      "Epoch 90/100\n",
      " - 2s - loss: 0.6813 - acc: 0.5587 - val_loss: 0.6819 - val_acc: 0.5678\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.6809 - acc: 0.5612 - val_loss: 0.6816 - val_acc: 0.5638\n",
      "Epoch 92/100\n",
      " - 2s - loss: 0.6824 - acc: 0.5595 - val_loss: 0.6816 - val_acc: 0.5647\n",
      "Epoch 93/100\n",
      " - 2s - loss: 0.6839 - acc: 0.5571 - val_loss: 0.6818 - val_acc: 0.5675\n",
      "Epoch 94/100\n",
      " - 2s - loss: 0.6826 - acc: 0.5573 - val_loss: 0.6828 - val_acc: 0.5600\n",
      "Epoch 95/100\n",
      " - 2s - loss: 0.6831 - acc: 0.5542 - val_loss: 0.6820 - val_acc: 0.5634\n",
      "Epoch 96/100\n",
      " - 2s - loss: 0.6818 - acc: 0.5588 - val_loss: 0.6821 - val_acc: 0.5638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 2s - loss: 0.6819 - acc: 0.5623 - val_loss: 0.6819 - val_acc: 0.5689\n",
      "Epoch 98/100\n",
      " - 2s - loss: 0.6817 - acc: 0.5645 - val_loss: 0.6815 - val_acc: 0.5674\n",
      "Epoch 99/100\n",
      " - 2s - loss: 0.6811 - acc: 0.5579 - val_loss: 0.6820 - val_acc: 0.5680\n",
      "Epoch 100/100\n",
      " - 2s - loss: 0.6823 - acc: 0.5590 - val_loss: 0.6814 - val_acc: 0.5656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13760fda0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple model per Yoon Kim (2014)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(10, 3, activation='selu', input_shape=(181, 4)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=100,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.6985 - acc: 0.5065 - val_loss: 0.6913 - val_acc: 0.5273\n",
      "Epoch 2/100\n",
      " - 7s - loss: 0.6924 - acc: 0.5181 - val_loss: 0.6912 - val_acc: 0.5105\n",
      "Epoch 3/100\n",
      " - 8s - loss: 0.6903 - acc: 0.5242 - val_loss: 0.6880 - val_acc: 0.5516\n",
      "Epoch 4/100\n",
      " - 8s - loss: 0.6891 - acc: 0.5333 - val_loss: 0.6859 - val_acc: 0.5624\n",
      "Epoch 5/100\n",
      " - 8s - loss: 0.6875 - acc: 0.5447 - val_loss: 0.6847 - val_acc: 0.5649\n",
      "Epoch 6/100\n",
      " - 8s - loss: 0.6859 - acc: 0.5521 - val_loss: 0.6844 - val_acc: 0.5532\n",
      "Epoch 7/100\n",
      " - 9s - loss: 0.6848 - acc: 0.5553 - val_loss: 0.6889 - val_acc: 0.5295\n",
      "Epoch 8/100\n",
      " - 8s - loss: 0.6837 - acc: 0.5546 - val_loss: 0.6829 - val_acc: 0.5653\n",
      "Epoch 9/100\n",
      " - 8s - loss: 0.6827 - acc: 0.5553 - val_loss: 0.6830 - val_acc: 0.5631\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.6819 - acc: 0.5549 - val_loss: 0.6815 - val_acc: 0.5624\n",
      "Epoch 11/100\n",
      " - 8s - loss: 0.6816 - acc: 0.5606 - val_loss: 0.6806 - val_acc: 0.5636\n",
      "Epoch 12/100\n",
      " - 8s - loss: 0.6814 - acc: 0.5621 - val_loss: 0.6840 - val_acc: 0.5454\n",
      "Epoch 13/100\n",
      " - 8s - loss: 0.6799 - acc: 0.5605 - val_loss: 0.6813 - val_acc: 0.5628\n",
      "Epoch 14/100\n",
      " - 8s - loss: 0.6795 - acc: 0.5662 - val_loss: 0.6817 - val_acc: 0.5579\n",
      "Epoch 15/100\n",
      " - 8s - loss: 0.6786 - acc: 0.5666 - val_loss: 0.6856 - val_acc: 0.5422\n",
      "Epoch 16/100\n",
      " - 8s - loss: 0.6790 - acc: 0.5657 - val_loss: 0.6799 - val_acc: 0.5678\n",
      "Epoch 17/100\n",
      " - 8s - loss: 0.6769 - acc: 0.5709 - val_loss: 0.6796 - val_acc: 0.5669\n",
      "Epoch 18/100\n",
      " - 8s - loss: 0.6765 - acc: 0.5739 - val_loss: 0.6790 - val_acc: 0.5684\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.6758 - acc: 0.5735 - val_loss: 0.6789 - val_acc: 0.5708\n",
      "Epoch 20/100\n",
      " - 8s - loss: 0.6756 - acc: 0.5738 - val_loss: 0.6793 - val_acc: 0.5669\n",
      "Epoch 21/100\n",
      " - 8s - loss: 0.6752 - acc: 0.5726 - val_loss: 0.6811 - val_acc: 0.5582\n",
      "Epoch 22/100\n",
      " - 8s - loss: 0.6744 - acc: 0.5755 - val_loss: 0.6808 - val_acc: 0.5656\n",
      "Epoch 23/100\n",
      " - 8s - loss: 0.6740 - acc: 0.5786 - val_loss: 0.6780 - val_acc: 0.5689\n",
      "Epoch 24/100\n",
      " - 8s - loss: 0.6749 - acc: 0.5782 - val_loss: 0.6798 - val_acc: 0.5694\n",
      "Epoch 25/100\n",
      " - 8s - loss: 0.6735 - acc: 0.5788 - val_loss: 0.6815 - val_acc: 0.5585\n",
      "Epoch 26/100\n",
      " - 8s - loss: 0.6728 - acc: 0.5805 - val_loss: 0.6806 - val_acc: 0.5641\n",
      "Epoch 27/100\n",
      " - 8s - loss: 0.6745 - acc: 0.5752 - val_loss: 0.6846 - val_acc: 0.5503\n",
      "Epoch 28/100\n",
      " - 8s - loss: 0.6726 - acc: 0.5801 - val_loss: 0.6909 - val_acc: 0.5441\n",
      "Epoch 29/100\n",
      " - 8s - loss: 0.6737 - acc: 0.5788 - val_loss: 0.6792 - val_acc: 0.5677\n",
      "Epoch 30/100\n",
      " - 8s - loss: 0.6714 - acc: 0.5846 - val_loss: 0.6775 - val_acc: 0.5733\n",
      "Epoch 31/100\n",
      " - 8s - loss: 0.6720 - acc: 0.5818 - val_loss: 0.6840 - val_acc: 0.5537\n",
      "Epoch 32/100\n",
      " - 8s - loss: 0.6711 - acc: 0.5849 - val_loss: 0.6869 - val_acc: 0.5523\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-69b69596c2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m model.fit(x_train, y_train, batch_size=50, epochs=100,\n\u001b[0;32m---> 14\u001b[0;31m           validation_data=(x_test, y_test), verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(100, 3, activation='selu', input_shape=(181, 4)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=100,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looks like extra filters (past 10) don't really help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now trying to use an example based on Kim's paper.\n",
    "# adapted from https://github.com/alexander-rakhlin/CNN-for-Sentence-Classification-in-Keras/blob/master/sentiment_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (15822, 181, 4)\n",
      "x_test shape: (6782, 181, 4)\n",
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.7457 - acc: 0.5034 - val_loss: 0.6917 - val_acc: 0.5227\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.6954 - acc: 0.5143 - val_loss: 0.6890 - val_acc: 0.5360\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.6920 - acc: 0.5245 - val_loss: 0.6884 - val_acc: 0.5382\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.6907 - acc: 0.5303 - val_loss: 0.6872 - val_acc: 0.5504\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.6899 - acc: 0.5362 - val_loss: 0.6873 - val_acc: 0.5481\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.6890 - acc: 0.5363 - val_loss: 0.6864 - val_acc: 0.5516\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.6882 - acc: 0.5449 - val_loss: 0.6862 - val_acc: 0.5512\n",
      "Epoch 8/100\n",
      " - 4s - loss: 0.6874 - acc: 0.5412 - val_loss: 0.6867 - val_acc: 0.5485\n",
      "Epoch 9/100\n",
      " - 4s - loss: 0.6871 - acc: 0.5454 - val_loss: 0.6850 - val_acc: 0.5509\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.6864 - acc: 0.5506 - val_loss: 0.6853 - val_acc: 0.5463\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.6857 - acc: 0.5497 - val_loss: 0.6841 - val_acc: 0.5510\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.6852 - acc: 0.5530 - val_loss: 0.6839 - val_acc: 0.5485\n",
      "Epoch 13/100\n",
      " - 4s - loss: 0.6845 - acc: 0.5509 - val_loss: 0.6832 - val_acc: 0.5615\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.6842 - acc: 0.5494 - val_loss: 0.6864 - val_acc: 0.5445\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.6827 - acc: 0.5544 - val_loss: 0.6827 - val_acc: 0.5574\n",
      "Epoch 16/100\n",
      " - 4s - loss: 0.6829 - acc: 0.5557 - val_loss: 0.6825 - val_acc: 0.5587\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.6826 - acc: 0.5592 - val_loss: 0.6826 - val_acc: 0.5597\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.6823 - acc: 0.5598 - val_loss: 0.6820 - val_acc: 0.5565\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.6813 - acc: 0.5625 - val_loss: 0.6818 - val_acc: 0.5618\n",
      "Epoch 20/100\n",
      " - 4s - loss: 0.6820 - acc: 0.5611 - val_loss: 0.6817 - val_acc: 0.5577\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.6806 - acc: 0.5644 - val_loss: 0.6819 - val_acc: 0.5644\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.6812 - acc: 0.5607 - val_loss: 0.6813 - val_acc: 0.5563\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.6793 - acc: 0.5607 - val_loss: 0.6812 - val_acc: 0.5656\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.6804 - acc: 0.5642 - val_loss: 0.6816 - val_acc: 0.5546\n",
      "Epoch 25/100\n",
      " - 4s - loss: 0.6804 - acc: 0.5592 - val_loss: 0.6807 - val_acc: 0.5652\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.6802 - acc: 0.5667 - val_loss: 0.6809 - val_acc: 0.5610\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.6793 - acc: 0.5681 - val_loss: 0.6828 - val_acc: 0.5603\n",
      "Epoch 28/100\n",
      " - 4s - loss: 0.6794 - acc: 0.5692 - val_loss: 0.6811 - val_acc: 0.5588\n",
      "Epoch 29/100\n",
      " - 4s - loss: 0.6792 - acc: 0.5698 - val_loss: 0.6821 - val_acc: 0.5518\n",
      "Epoch 30/100\n",
      " - 4s - loss: 0.6767 - acc: 0.5708 - val_loss: 0.6807 - val_acc: 0.5562\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4cd8589f6b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n\u001b[0;32m---> 73\u001b[0;31m           validation_data=(x_test, y_test), verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/NovoNordisk_Capstone/.env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train convolutional network for sentiment analysis on IMDB corpus. Based on\n",
    "\"Convolutional Neural Networks for Sentence Classification\" by Yoon Kim\n",
    "http://arxiv.org/pdf/1408.5882v2.pdf\n",
    "For \"CNN-rand\" and \"CNN-non-static\" gets to 88-90%, and \"CNN-static\" - 85% after 2-5 epochs with following settings:\n",
    "embedding_dim = 50          \n",
    "filter_sizes = (3, 8)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "Differences from original article:\n",
    "- larger IMDB corpus, longer sentences; sentence length is very important, just like data size\n",
    "- smaller embedding dimension, 50 instead of 300\n",
    "- 2 filter sizes instead of original 3\n",
    "- fewer filters; original work uses 100, experiments show that 3-10 is enough;\n",
    "- random initialization is no worse than word2vec init on IMDB corpus\n",
    "- sliding Max Pooling instead of original Global Pooling\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, GlobalMaxPooling1D, Convolution1D\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 4\n",
    "filter_sizes = (3, 4, 5)\n",
    "num_filters = 10\n",
    "dropout_prob = 0.5\n",
    "hidden_dims = 50\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 50\n",
    "num_epochs = 100\n",
    "\n",
    "# Prepossessing parameters\n",
    "sequence_length = 181\n",
    "\n",
    "\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "# prepare input shape\n",
    "input_shape = (sequence_length, embedding_dim)\n",
    "model_input = Input(shape=input_shape)\n",
    "z = model_input\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"selu\",\n",
    "                         strides=1)(z)\n",
    "    conv = GlobalMaxPooling1D()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob)(z)\n",
    "#z = Dense(hidden_dims, activation=\"selu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.6929 - acc: 0.5056 - val_loss: 0.6908 - val_acc: 0.5252\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.6924 - acc: 0.5157 - val_loss: 0.6900 - val_acc: 0.5276\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.6916 - acc: 0.5257 - val_loss: 0.6903 - val_acc: 0.5279\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.6900 - acc: 0.5331 - val_loss: 0.6859 - val_acc: 0.5535\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.6880 - acc: 0.5390 - val_loss: 0.6860 - val_acc: 0.5522\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.6863 - acc: 0.5454 - val_loss: 0.6847 - val_acc: 0.5597\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.6836 - acc: 0.5566 - val_loss: 0.6828 - val_acc: 0.5649\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.6811 - acc: 0.5607 - val_loss: 0.6805 - val_acc: 0.5681\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.6786 - acc: 0.5691 - val_loss: 0.6864 - val_acc: 0.5543\n",
      "Epoch 10/10\n",
      " - 9s - loss: 0.6763 - acc: 0.5759 - val_loss: 0.6807 - val_acc: 0.5705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138ba8a20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(181, 4)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=10,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.6971 - acc: 0.5214 - val_loss: 0.6944 - val_acc: 0.5029\n",
      "Epoch 2/10\n",
      " - 15s - loss: 0.6946 - acc: 0.5168 - val_loss: 0.6933 - val_acc: 0.5099\n",
      "Epoch 3/10\n",
      " - 15s - loss: 0.6922 - acc: 0.5257 - val_loss: 0.6902 - val_acc: 0.5218\n",
      "Epoch 4/10\n",
      " - 15s - loss: 0.6923 - acc: 0.5216 - val_loss: 0.6892 - val_acc: 0.5434\n",
      "Epoch 5/10\n",
      " - 15s - loss: 0.6909 - acc: 0.5296 - val_loss: 0.6905 - val_acc: 0.5223\n",
      "Epoch 6/10\n",
      " - 14s - loss: 0.6896 - acc: 0.5373 - val_loss: 0.6919 - val_acc: 0.5159\n",
      "Epoch 7/10\n",
      " - 14s - loss: 0.6899 - acc: 0.5321 - val_loss: 0.6881 - val_acc: 0.5414\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.6905 - acc: 0.5318 - val_loss: 0.6894 - val_acc: 0.5320\n",
      "Epoch 9/10\n",
      " - 14s - loss: 0.6885 - acc: 0.5422 - val_loss: 0.6868 - val_acc: 0.5569\n",
      "Epoch 10/10\n",
      " - 14s - loss: 0.6892 - acc: 0.5378 - val_loss: 0.6855 - val_acc: 0.5618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x134423ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='selu', input_shape=(181, 4)))\n",
    "model.add(Conv1D(64, 3, activation='selu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='selu'))\n",
    "model.add(Conv1D(128, 3, activation='selu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=10,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15822 samples, validate on 6782 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.6939 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5068\n",
      "Epoch 2/10\n",
      " - 10s - loss: 0.6932 - acc: 0.5027 - val_loss: 0.6930 - val_acc: 0.4937\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.6920 - acc: 0.5228 - val_loss: 0.6905 - val_acc: 0.5354\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.6891 - acc: 0.5391 - val_loss: 0.6881 - val_acc: 0.5479\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.6875 - acc: 0.5463 - val_loss: 0.6884 - val_acc: 0.5472\n",
      "Epoch 6/10\n",
      " - 10s - loss: 0.6853 - acc: 0.5518 - val_loss: 0.6867 - val_acc: 0.5495\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.6833 - acc: 0.5599 - val_loss: 0.6868 - val_acc: 0.5506\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.6816 - acc: 0.5590 - val_loss: 0.6874 - val_acc: 0.5444\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.6791 - acc: 0.5698 - val_loss: 0.6879 - val_acc: 0.5510\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.6794 - acc: 0.5698 - val_loss: 0.6887 - val_acc: 0.5535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13bf07f28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(181, 4)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=50, epochs=10,\n",
    "          validation_data=(x_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Novo Capstone",
   "language": "python",
   "name": "novo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
