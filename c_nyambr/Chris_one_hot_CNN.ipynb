{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.layers.merge import Concatenate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in high and low expression one_hot files\n",
    "#high_exp = pd.concat(\n",
    "#    [pd.read_csv(\"../c_nyambr/high_exp_one_hot_{i}.csv\", index_col=0)\n",
    "#     for i in range(1, 5)])\n",
    "#low_exp = pd.concat(\n",
    "#    [pd.read_csv(\"../c_nyambr/low_exp_one_hot_{i}.csv\", index_col=0)\n",
    "#     for i in range(1, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high_exp = pd.concat([pd.read_csv('high_exp_one_hot_1.csv',index_col=0),\n",
    "                      pd.read_csv('high_exp_one_hot_2.csv',index_col=0),\n",
    "                      pd.read_csv('high_exp_one_hot_3.csv',index_col=0),\n",
    "                      pd.read_csv('high_exp_one_hot_4.csv',index_col=0)])\n",
    "low_exp = pd.concat([pd.read_csv('low_exp_one_hot_1.csv',index_col=0),\n",
    "                      pd.read_csv('low_exp_one_hot_2.csv',index_col=0),\n",
    "                      pd.read_csv('low_exp_one_hot_3.csv',index_col=0),\n",
    "                      pd.read_csv('low_exp_one_hot_4.csv',index_col=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate to form a single dataframe\n",
    "data_df = pd.concat([high_exp, low_exp], axis=0)\n",
    "\n",
    "#pandas doesn't know how read multiple data types, so they're saved as strings \n",
    "\n",
    "# function to convert csv files into \n",
    "def string_to_matrix(string):\n",
    "    # convert string to list of one_hot lists\n",
    "    string = str(string)\n",
    "    list_of_strings = string.split('], [')\n",
    "    list_of_lists = [channels.strip().replace('[', '').replace(']', '').replace(',', '').split() \n",
    "                     for channels in list_of_strings\n",
    "                     if 'nan' not in list_of_strings\n",
    "                    ]\n",
    "    # add padding\n",
    "    remaining_pad = 181 - len(list_of_lists)\n",
    "    while remaining_pad > 0:\n",
    "        list_of_lists.append(list([0 for x in range(0, 64)]))\n",
    "        remaining_pad = remaining_pad - 1\n",
    "    # return padded one_hot matrix\n",
    "    return np.array(list_of_lists).astype(np.float)\n",
    "\n",
    "data_df['one_hot_matrix'] = data_df['one_hot_matrix'].apply(string_to_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get X and y data from data_df\n",
    "max_len = 181\n",
    "width = 64\n",
    "\n",
    "X = np.zeros((22615, max_len, width))\n",
    "for idx, one_hot_matrix in enumerate(data_df['one_hot_matrix'].values):\n",
    "    X[idx, :, :] = one_hot_matrix\n",
    "\n",
    "y = data_df['class'].values\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tune hyperparameters for simple model\n",
    "# define simple model per Yoon Kim (2014)\n",
    "def create_model(filter_sizes=3, num_filters=10):\n",
    "    # prepare input shape\n",
    "    input_shape = (181, 64)\n",
    "    model_input = Input(shape=input_shape)\n",
    "    z = model_input\n",
    "\n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"valid\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(z)\n",
    "        conv = MaxPooling1D()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "    z = Dropout(0.5)(z)\n",
    "    model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lusers/cnyambr/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /usr/lusers/cnyambr/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x2b48c2a451e0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/sw/anaconda.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x2b48c2a451e0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/sw/anaconda.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4D199B2F421E4B7285BECF16FC70B49C']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4D199B2F421E4B7285BECF16FC70B49C'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-c76899647ba6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>\n        result = <ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>, result=<ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>\n        self.user_global_ns = {'Concatenate': <class 'keras.layers.merge.Concatenate'>, 'Convolution1D': <class 'keras.layers.convolutional.Conv1D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GlobalMaxPooling1D': <class 'keras.layers.pooling.GlobalMaxPooling1D'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...eras.wrappers.scikit_learn import KerasClassifier', \"high_exp = pd.concat([pd.read_csv('high_exp_one_...d.read_csv('low_exp_one_hot_4.csv',index_col=0)])\", \"# concatenate to form a single dataframe\\ndata_df...data_df['one_hot_matrix'].apply(string_to_matrix)\", '# get X and y data from data_df\\nmax_len = 181\\nwi..._split(\\n    X, y, test_size=0.3, random_state=42)', '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\", '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\"], 'Input': <function Input>, 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'MaxPooling1D': <class 'keras.layers.pooling.MaxPooling1D'>, ...}\n        self.user_ns = {'Concatenate': <class 'keras.layers.merge.Concatenate'>, 'Convolution1D': <class 'keras.layers.convolutional.Conv1D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GlobalMaxPooling1D': <class 'keras.layers.pooling.GlobalMaxPooling1D'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...eras.wrappers.scikit_learn import KerasClassifier', \"high_exp = pd.concat([pd.read_csv('high_exp_one_...d.read_csv('low_exp_one_hot_4.csv',index_col=0)])\", \"# concatenate to form a single dataframe\\ndata_df...data_df['one_hot_matrix'].apply(string_to_matrix)\", '# get X and y data from data_df\\nmax_len = 181\\nwi..._split(\\n    X, y, test_size=0.3, random_state=42)', '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\", '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\"], 'Input': <function Input>, 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'MaxPooling1D': <class 'keras.layers.pooling.MaxPooling1D'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/gscratch/pfaendtner/cnyambura/NovoNordisk_Capstone/c_nyambr/<ipython-input-8-c76899647ba6> in <module>()\n     15 \n     16 param_grid = dict(filter_sizes=filter_sizes, num_filters=num_filters)\n     17 \n     18 grid = GridSearchCV(estimator=model, param_grid=param_grid,\n     19                     cv=10, n_jobs=-1)\n---> 20 grid_result = grid.fit(x_train, y_train)\n     21 # summarize results\n     22 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n     23 \n     24 grid_df = pd.DataFrame(grid_result.cv_results_['params'])\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...train_score=True,\n       scoring=None, verbose=0), X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 1, 1, ..., 1, 1, 0])\n        groups = None\n        self.param_grid = {'filter_sizes': [(3, 3, 3), (3, 4, 5), (5, 5, 5), (3, 5, 7), (7, 7, 7), (5, 7, 10), (10, 10, 10), (3, 4, 5, 6)], 'num_filters': [10, 20, 50, 100, 200]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...train_score=True,\n       scoring=None, verbose=0), X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri May  4 12:16:59 2018\nPID: 27389              Python 3.6.0: /sw/anaconda-4.3.1/python3/bin/python\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), scorer=<function _passthrough_scorer>, train=array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), test=array([   0,    1,    2, ..., 1580, 1581, 1582]), verbose=0, parameters={'filter_sizes': (3, 3, 3), 'num_filters': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y_train = array([0, 0, 0, ..., 1, 1, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.training.Model object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        fit_args = {'batch_size': 50, 'epochs': 25, 'verbose': 2}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), batch_size=50, epochs=25, verbose=2, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1625         # Validate user data.\n   1626         x, y, sample_weights = self._standardize_user_data(\n   1627             x, y,\n   1628             sample_weight=sample_weight,\n   1629             class_weight=class_weight,\n-> 1630             batch_size=batch_size)\n        batch_size = 50\n   1631         # Prepare validation data.\n   1632         do_validation = False\n   1633         if validation_data:\n   1634             do_validation = True\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_user_data(self=<keras.engine.training.Model object>, x=[memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])], y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=50)\n   1475                                     check_batch_axis=False,\n   1476                                     exception_prefix='input')\n   1477         y = _standardize_input_data(y, self._feed_output_names,\n   1478                                     output_shapes,\n   1479                                     check_batch_axis=False,\n-> 1480                                     exception_prefix='target')\n   1481         sample_weights = _standardize_sample_weights(sample_weight,\n   1482                                                      self._feed_output_names)\n   1483         class_weights = _standardize_class_weights(class_weight,\n   1484                                                    self._feed_output_names)\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [0]])], names=['dense_1'], shapes=[(None, 89, 1)], check_batch_axis=False, exception_prefix='target')\n    108                 if data[i].ndim != len(shape):\n    109                     raise ValueError(\n    110                         'Error when checking ' + exception_prefix +\n    111                         ': expected ' + names[i] + ' to have ' +\n    112                         str(len(shape)) + ' dimensions, but got array '\n--> 113                         'with shape ' + str(data_shape))\n        data_shape = (14247, 1)\n    114                 if not check_batch_axis:\n    115                     data_shape = data_shape[1:]\n    116                     shape = shape[1:]\n    117                 for dim, ref_dim in zip(data_shape, shape):\n\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (14247, 1)\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 151, in fit\n    history = self.model.fit(x, y, **fit_args)\n  File \"/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 1630, in fit\n    batch_size=batch_size)\n  File \"/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 1480, in _standardize_user_data\n    exception_prefix='target')\n  File \"/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py\", line 113, in _standardize_input_data\n    'with shape ' + str(data_shape))\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (14247, 1)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri May  4 12:16:59 2018\nPID: 27389              Python 3.6.0: /sw/anaconda-4.3.1/python3/bin/python\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), scorer=<function _passthrough_scorer>, train=array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), test=array([   0,    1,    2, ..., 1580, 1581, 1582]), verbose=0, parameters={'filter_sizes': (3, 3, 3), 'num_filters': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y_train = array([0, 0, 0, ..., 1, 1, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.training.Model object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        fit_args = {'batch_size': 50, 'epochs': 25, 'verbose': 2}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), batch_size=50, epochs=25, verbose=2, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1625         # Validate user data.\n   1626         x, y, sample_weights = self._standardize_user_data(\n   1627             x, y,\n   1628             sample_weight=sample_weight,\n   1629             class_weight=class_weight,\n-> 1630             batch_size=batch_size)\n        batch_size = 50\n   1631         # Prepare validation data.\n   1632         do_validation = False\n   1633         if validation_data:\n   1634             do_validation = True\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_user_data(self=<keras.engine.training.Model object>, x=[memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])], y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=50)\n   1475                                     check_batch_axis=False,\n   1476                                     exception_prefix='input')\n   1477         y = _standardize_input_data(y, self._feed_output_names,\n   1478                                     output_shapes,\n   1479                                     check_batch_axis=False,\n-> 1480                                     exception_prefix='target')\n   1481         sample_weights = _standardize_sample_weights(sample_weight,\n   1482                                                      self._feed_output_names)\n   1483         class_weights = _standardize_class_weights(class_weight,\n   1484                                                    self._feed_output_names)\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [0]])], names=['dense_1'], shapes=[(None, 89, 1)], check_batch_axis=False, exception_prefix='target')\n    108                 if data[i].ndim != len(shape):\n    109                     raise ValueError(\n    110                         'Error when checking ' + exception_prefix +\n    111                         ': expected ' + names[i] + ' to have ' +\n    112                         str(len(shape)) + ' dimensions, but got array '\n--> 113                         'with shape ' + str(data_shape))\n        data_shape = (14247, 1)\n    114                 if not check_batch_axis:\n    115                     data_shape = data_shape[1:]\n    116                     shape = shape[1:]\n    117                 for dim, ref_dim in zip(data_shape, shape):\n\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (14247, 1)\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri May  4 12:16:59 2018\nPID: 27389              Python 3.6.0: /sw/anaconda-4.3.1/python3/bin/python\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), scorer=<function _passthrough_scorer>, train=array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), test=array([   0,    1,    2, ..., 1580, 1581, 1582]), verbose=0, parameters={'filter_sizes': (3, 3, 3), 'num_filters': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y_train = array([0, 0, 0, ..., 1, 1, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.training.Model object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        fit_args = {'batch_size': 50, 'epochs': 25, 'verbose': 2}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), batch_size=50, epochs=25, verbose=2, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1625         # Validate user data.\n   1626         x, y, sample_weights = self._standardize_user_data(\n   1627             x, y,\n   1628             sample_weight=sample_weight,\n   1629             class_weight=class_weight,\n-> 1630             batch_size=batch_size)\n        batch_size = 50\n   1631         # Prepare validation data.\n   1632         do_validation = False\n   1633         if validation_data:\n   1634             do_validation = True\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_user_data(self=<keras.engine.training.Model object>, x=[memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])], y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=50)\n   1475                                     check_batch_axis=False,\n   1476                                     exception_prefix='input')\n   1477         y = _standardize_input_data(y, self._feed_output_names,\n   1478                                     output_shapes,\n   1479                                     check_batch_axis=False,\n-> 1480                                     exception_prefix='target')\n   1481         sample_weights = _standardize_sample_weights(sample_weight,\n   1482                                                      self._feed_output_names)\n   1483         class_weights = _standardize_class_weights(class_weight,\n   1484                                                    self._feed_output_names)\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [0]])], names=['dense_1'], shapes=[(None, 89, 1)], check_batch_axis=False, exception_prefix='target')\n    108                 if data[i].ndim != len(shape):\n    109                     raise ValueError(\n    110                         'Error when checking ' + exception_prefix +\n    111                         ': expected ' + names[i] + ' to have ' +\n    112                         str(len(shape)) + ' dimensions, but got array '\n--> 113                         'with shape ' + str(data_shape))\n        data_shape = (14247, 1)\n    114                 if not check_batch_axis:\n    115                     data_shape = data_shape[1:]\n    116                     shape = shape[1:]\n    117                 for dim, ref_dim in zip(data_shape, shape):\n\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (14247, 1)\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c76899647ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m grid = GridSearchCV(estimator=model, param_grid=param_grid,\n\u001b[1;32m     19\u001b[0m                     cv=10, n_jobs=-1)\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x2b48c2a451e0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/sw/anaconda.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x2b48c2a451e0, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/sw/anaconda.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4D199B2F421E4B7285BECF16FC70B49C']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4D199B2F421E4B7285BECF16FC70B49C'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2018-05-04T12:16:52.186999', 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'session': '4D199B2F421E4B7285BECF16FC70B49C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '2E4C79E2A1844ACB84AB6D72BD12FAF5', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# fix random seed for reproducibility\\nseed = 7\\nn...v file\\ngrid_df.to_csv('grid_search_results.csv')\\n\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-c76899647ba6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>\n        result = <ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>, result=<ExecutionResult object at 2b493fd5e7b8, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x2b493fe0c780, file \"<ipython-input-8-c76899647ba6>\", line 20>\n        self.user_global_ns = {'Concatenate': <class 'keras.layers.merge.Concatenate'>, 'Convolution1D': <class 'keras.layers.convolutional.Conv1D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GlobalMaxPooling1D': <class 'keras.layers.pooling.GlobalMaxPooling1D'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...eras.wrappers.scikit_learn import KerasClassifier', \"high_exp = pd.concat([pd.read_csv('high_exp_one_...d.read_csv('low_exp_one_hot_4.csv',index_col=0)])\", \"# concatenate to form a single dataframe\\ndata_df...data_df['one_hot_matrix'].apply(string_to_matrix)\", '# get X and y data from data_df\\nmax_len = 181\\nwi..._split(\\n    X, y, test_size=0.3, random_state=42)', '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\", '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\"], 'Input': <function Input>, 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'MaxPooling1D': <class 'keras.layers.pooling.MaxPooling1D'>, ...}\n        self.user_ns = {'Concatenate': <class 'keras.layers.merge.Concatenate'>, 'Convolution1D': <class 'keras.layers.convolutional.Conv1D'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GlobalMaxPooling1D': <class 'keras.layers.pooling.GlobalMaxPooling1D'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\nimport ma...eras.wrappers.scikit_learn import KerasClassifier', \"high_exp = pd.concat([pd.read_csv('high_exp_one_...d.read_csv('low_exp_one_hot_4.csv',index_col=0)])\", \"# concatenate to form a single dataframe\\ndata_df...data_df['one_hot_matrix'].apply(string_to_matrix)\", '# get X and y data from data_df\\nmax_len = 181\\nwi..._split(\\n    X, y, test_size=0.3, random_state=42)', '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\", '# tune hyperparameters for simple model\\n# define...          metrics=[\"accuracy\"])\\n\\n    return model', \"# fix random seed for reproducibility\\nseed = 7\\nn...sv file\\ngrid_df.to_csv('grid_search_results.csv')\"], 'Input': <function Input>, 'KerasClassifier': <class 'keras.wrappers.scikit_learn.KerasClassifier'>, 'MaxPooling1D': <class 'keras.layers.pooling.MaxPooling1D'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/gscratch/pfaendtner/cnyambura/NovoNordisk_Capstone/c_nyambr/<ipython-input-8-c76899647ba6> in <module>()\n     15 \n     16 param_grid = dict(filter_sizes=filter_sizes, num_filters=num_filters)\n     17 \n     18 grid = GridSearchCV(estimator=model, param_grid=param_grid,\n     19                     cv=10, n_jobs=-1)\n---> 20 grid_result = grid.fit(x_train, y_train)\n     21 # summarize results\n     22 print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n     23 \n     24 grid_df = pd.DataFrame(grid_result.cv_results_['params'])\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...train_score=True,\n       scoring=None, verbose=0), X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 1, 1, ..., 1, 1, 0])\n        groups = None\n        self.param_grid = {'filter_sizes': [(3, 3, 3), (3, 4, 5), (5, 5, 5), (3, 5, 7), (7, 7, 7), (5, 7, 10), (10, 10, 10), (3, 4, 5, 6)], 'num_filters': [10, 20, 50, 100, 200]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=10, error_score='raise',\n       ...train_score=True,\n       scoring=None, verbose=0), X=array([[[0., 0., 0., ..., 0., 0., 0.],\n        [...0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri May  4 12:16:59 2018\nPID: 27389              Python 3.6.0: /sw/anaconda-4.3.1/python3/bin/python\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<keras.wrappers.scikit_learn.KerasClassifier object>, memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), array([0, 1, 1, ..., 1, 1, 0]), <function _passthrough_scorer>, array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), array([   0,    1,    2, ..., 1580, 1581, 1582]), 0, {'filter_sizes': (3, 3, 3), 'num_filters': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/sw/anaconda-4.3.1/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=<keras.wrappers.scikit_learn.KerasClassifier object>, X=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 1, 1, ..., 1, 1, 0]), scorer=<function _passthrough_scorer>, train=array([ 1583,  1584,  1585, ..., 15827, 15828, 15829]), test=array([   0,    1,    2, ..., 1580, 1581, 1582]), verbose=0, parameters={'filter_sizes': (3, 3, 3), 'num_filters': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        X_train = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y_train = array([0, 0, 0, ..., 1, 1, 0])\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, **kwargs={})\n    204         else:\n    205             raise ValueError('Invalid shape for y: ' + str(y.shape))\n    206         self.n_classes_ = len(self.classes_)\n    207         if sample_weight is not None:\n    208             kwargs['sample_weight'] = sample_weight\n--> 209         return super(KerasClassifier, self).fit(x, y, **kwargs)\n        self.fit = <bound method KerasClassifier.fit of <keras.wrappers.scikit_learn.KerasClassifier object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        kwargs = {}\n    210 \n    211     def predict(self, x, **kwargs):\n    212         \"\"\"Returns the class predictions for the given test data.\n    213 \n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py in fit(self=<keras.wrappers.scikit_learn.KerasClassifier object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), **kwargs={})\n    146             y = to_categorical(y)\n    147 \n    148         fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n    149         fit_args.update(kwargs)\n    150 \n--> 151         history = self.model.fit(x, y, **fit_args)\n        history = undefined\n        self.model.fit = <bound method Model.fit of <keras.engine.training.Model object>>\n        x = memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])\n        y = array([0, 0, 0, ..., 1, 1, 0])\n        fit_args = {'batch_size': 50, 'epochs': 25, 'verbose': 2}\n    152 \n    153         return history\n    154 \n    155     def filter_sk_params(self, fn, override=None):\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in fit(self=<keras.engine.training.Model object>, x=memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]), y=array([0, 0, 0, ..., 1, 1, 0]), batch_size=50, epochs=25, verbose=2, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs={})\n   1625         # Validate user data.\n   1626         x, y, sample_weights = self._standardize_user_data(\n   1627             x, y,\n   1628             sample_weight=sample_weight,\n   1629             class_weight=class_weight,\n-> 1630             batch_size=batch_size)\n        batch_size = 50\n   1631         # Prepare validation data.\n   1632         do_validation = False\n   1633         if validation_data:\n   1634             do_validation = True\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_user_data(self=<keras.engine.training.Model object>, x=[memmap([[[0., 0., 0., ..., 0., 0., 0.],\n        ...., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]])], y=array([0, 0, 0, ..., 1, 1, 0]), sample_weight=None, class_weight=None, check_array_lengths=True, batch_size=50)\n   1475                                     check_batch_axis=False,\n   1476                                     exception_prefix='input')\n   1477         y = _standardize_input_data(y, self._feed_output_names,\n   1478                                     output_shapes,\n   1479                                     check_batch_axis=False,\n-> 1480                                     exception_prefix='target')\n   1481         sample_weights = _standardize_sample_weights(sample_weight,\n   1482                                                      self._feed_output_names)\n   1483         class_weights = _standardize_class_weights(class_weight,\n   1484                                                    self._feed_output_names)\n\n...........................................................................\n/usr/lusers/cnyambr/.local/lib/python3.6/site-packages/keras/engine/training.py in _standardize_input_data(data=[array([[0],\n       [0],\n       [0],\n       ...,\n       [1],\n       [1],\n       [0]])], names=['dense_1'], shapes=[(None, 89, 1)], check_batch_axis=False, exception_prefix='target')\n    108                 if data[i].ndim != len(shape):\n    109                     raise ValueError(\n    110                         'Error when checking ' + exception_prefix +\n    111                         ': expected ' + names[i] + ' to have ' +\n    112                         str(len(shape)) + ' dimensions, but got array '\n--> 113                         'with shape ' + str(data_shape))\n        data_shape = (14247, 1)\n    114                 if not check_batch_axis:\n    115                     data_shape = data_shape[1:]\n    116                     shape = shape[1:]\n    117                 for dim, ref_dim in zip(data_shape, shape):\n\nValueError: Error when checking target: expected dense_1 to have 3 dimensions, but got array with shape (14247, 1)\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=50,\n",
    "                        epochs=25, verbose=2)\n",
    "\n",
    "# define the grid search parameters\n",
    "# model hyperparameters\n",
    "filter_sizes = [(3, 3, 3), (3, 4, 5), (5, 5, 5),\n",
    "               (3, 5, 7), (7, 7, 7), (5, 7, 10),\n",
    "               (10, 10, 10), (3, 4, 5, 6)]\n",
    "num_filters = [10, 20, 50, 100, 200]\n",
    "\n",
    "\n",
    "param_grid = dict(filter_sizes=filter_sizes, num_filters=num_filters)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                    cv=10, n_jobs=-1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "grid_df = pd.DataFrame(grid_result.cv_results_['params'])\n",
    "grid_df['means'] = grid_result.cv_results_['mean_test_score']\n",
    "grid_df['stddev'] = grid_result.cv_results_['std_test_score']\n",
    "\n",
    "# print results to csv file\n",
    "grid_df.to_csv('grid_search_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search_data = pd.read_csv('first_grid_search_results.csv', index_col=0)\n",
    "grid_search_data.sort_values('means', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Pearson correlation of each hyperparameter \\nwith accuracy '\n",
    "      'from 10-fold cv:')\n",
    "grid_search_data.corr()['means'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = grid_search_data.groupby('filter_size')\n",
    "grouped.mean()['means'].plot(yerr=grouped.mean()['stddev'], marker='o', ms=7, mfc='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = grid_search_data.groupby(['pool_size', 'filter_size'])\n",
    "grouped.mean()['means'].plot(yerr=grouped.mean()['stddev'], marker='o', ms=7, mfc='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = grid_search_data.groupby('pool_size')\n",
    "grouped.mean()['means'].plot(yerr=grouped.mean()['stddev'], marker='o', ms=7, mfc='k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
